{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import six\n",
    "import tensorflow as tf\n",
    "\n",
    "from deepchem.data import NumpyDataset\n",
    "from deepchem.feat.graph_features import ConvMolFeaturizer\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.models.tensorgraph.graph_layers import WeaveGather, \\\n",
    "    DTNNEmbedding, DTNNStep, DTNNGather, DAGLayer, \\\n",
    "    DAGGather, DTNNExtract, MessagePassing, SetGather\n",
    "from deepchem.models.tensorgraph.graph_layers import WeaveLayerFactory\n",
    "from deepchem.models.tensorgraph.layers import Dense, SoftMax, \\\n",
    "    SoftMaxCrossEntropy, GraphConv, BatchNorm, \\\n",
    "    GraphPool, GraphGather, WeightedError, Dropout, BatchNormalization, Stack, Flatten, GraphCNN, GraphCNNPool\n",
    "from deepchem.models.tensorgraph.layers import L2Loss, Label, Weights, Feature\n",
    "from deepchem.models.tensorgraph.tensor_graph import TensorGraph\n",
    "from deepchem.trans import undo_transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNNTensorGraph(TensorGraph):\n",
    "  \"\"\" Message Passing Neural Network,\n",
    "      default structures built according to https://arxiv.org/abs/1511.06391 \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               n_tasks,\n",
    "               n_atom_feat=70,\n",
    "               n_pair_feat=8,\n",
    "               n_hidden=100,\n",
    "               T=5,\n",
    "               M=10,\n",
    "               mode=\"regression\",\n",
    "               **kwargs):\n",
    "    \"\"\"\n",
    "            Parameters\n",
    "            ----------\n",
    "            n_tasks: int\n",
    "              Number of tasks\n",
    "            n_atom_feat: int, optional\n",
    "              Number of features per atom.\n",
    "            n_pair_feat: int, optional\n",
    "              Number of features per pair of atoms.\n",
    "            n_hidden: int, optional\n",
    "              Number of units(convolution depths) in corresponding hidden layer\n",
    "            n_graph_feat: int, optional\n",
    "              Number of output features for each molecule(graph)\n",
    "\n",
    "            \"\"\"\n",
    "    self.n_tasks = n_tasks\n",
    "    self.n_atom_feat = n_atom_feat\n",
    "    self.n_pair_feat = n_pair_feat\n",
    "    self.n_hidden = n_hidden\n",
    "    self.T = T\n",
    "    self.M = M\n",
    "    self.mode = mode\n",
    "    super(MPNNTensorGraph, self).__init__(**kwargs)\n",
    "    self.build_graph()\n",
    "\n",
    "  def build_graph(self):\n",
    "    # Build placeholders\n",
    "    self.atom_features = Feature(shape=(None, self.n_atom_feat))\n",
    "    self.pair_features = Feature(shape=(None, self.n_pair_feat))\n",
    "    self.atom_split = Feature(shape=(None,), dtype=tf.int32)\n",
    "    self.atom_to_pair = Feature(shape=(None, 2), dtype=tf.int32)\n",
    "\n",
    "    message_passing = MessagePassing(\n",
    "        self.T,\n",
    "        message_fn='enn',\n",
    "        update_fn='gru',\n",
    "        n_hidden=self.n_hidden,\n",
    "        in_layers=[self.atom_features, self.pair_features, self.atom_to_pair])\n",
    "\n",
    "    atom_embeddings = Dense(self.n_hidden, in_layers=[message_passing])\n",
    "\n",
    "    mol_embeddings = SetGather(\n",
    "        self.M,\n",
    "        self.batch_size,\n",
    "        n_hidden=self.n_hidden,\n",
    "        in_layers=[atom_embeddings, self.atom_split])\n",
    "\n",
    "    dense1 = Dense(\n",
    "        out_channels=2 * self.n_hidden,\n",
    "        activation_fn=tf.nn.relu,\n",
    "        in_layers=[mol_embeddings])\n",
    "    costs = []\n",
    "    self.labels_fd = []\n",
    "    for task in range(self.n_tasks):\n",
    "      if self.mode == \"classification\":\n",
    "        classification = Dense(\n",
    "            out_channels=2, activation_fn=None, in_layers=[dense1])\n",
    "        softmax = SoftMax(in_layers=[classification])\n",
    "        self.add_output(softmax)\n",
    "\n",
    "        label = Label(shape=(None, 2))\n",
    "        self.labels_fd.append(label)\n",
    "        cost = SoftMaxCrossEntropy(in_layers=[label, classification])\n",
    "        costs.append(cost)\n",
    "      if self.mode == \"regression\":\n",
    "        regression = Dense(\n",
    "            out_channels=1, activation_fn=None, in_layers=[dense1])\n",
    "        self.add_output(regression)\n",
    "\n",
    "        label = Label(shape=(None, 1))\n",
    "        self.labels_fd.append(label)\n",
    "        cost = L2Loss(in_layers=[label, regression])\n",
    "        costs.append(cost)\n",
    "    if self.mode == \"classification\":\n",
    "      all_cost = Stack(in_layers=costs, axis=1)\n",
    "    elif self.mode == \"regression\":\n",
    "      all_cost = Stack(in_layers=costs, axis=1)\n",
    "    self.weights = Weights(shape=(None, self.n_tasks))\n",
    "    loss = WeightedError(in_layers=[all_cost, self.weights])\n",
    "    self.set_loss(loss)\n",
    "\n",
    "  def default_generator(self,\n",
    "                        dataset,\n",
    "                        validdataset,\n",
    "                        metrics,\n",
    "                        transformers=[],\n",
    "                        epochs=1,\n",
    "                        predict=False,\n",
    "                        deterministic=True,\n",
    "                        pad_batches=True):\n",
    "    \"\"\" Same generator as Weave models \"\"\"\n",
    "    \n",
    "    global train_metric\n",
    "    global valid_metric\n",
    "    train_metric=[]\n",
    "    valid_metric=[]    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "      if not predict:\n",
    "        print('Starting epoch %i' % epoch)\n",
    "      for (X_b, y_b, w_b, ids_b) in dataset.iterbatches(\n",
    "          batch_size=self.batch_size,\n",
    "          deterministic=deterministic,\n",
    "          pad_batches=pad_batches):\n",
    "\n",
    "        feed_dict = dict()\n",
    "        if y_b is not None:\n",
    "          for index, label in enumerate(self.labels_fd):\n",
    "            if self.mode == \"classification\":\n",
    "              feed_dict[label] = to_one_hot(y_b[:, index])\n",
    "            if self.mode == \"regression\":\n",
    "              feed_dict[label] = y_b[:, index:index + 1]\n",
    "        # w_b act as the indicator of unique samples in the batch\n",
    "        if w_b is not None:\n",
    "          feed_dict[self.weights] = w_b\n",
    "\n",
    "        atom_feat = []\n",
    "        pair_feat = []\n",
    "        atom_split = []\n",
    "        atom_to_pair = []\n",
    "        pair_split = []\n",
    "        start = 0\n",
    "        for im, mol in enumerate(X_b):\n",
    "          n_atoms = mol.get_num_atoms()\n",
    "          # number of atoms in each molecule\n",
    "          atom_split.extend([im] * n_atoms)\n",
    "          # index of pair features\n",
    "          C0, C1 = np.meshgrid(np.arange(n_atoms), np.arange(n_atoms))\n",
    "          atom_to_pair.append(\n",
    "              np.transpose(\n",
    "                  np.array([C1.flatten() + start,\n",
    "                            C0.flatten() + start])))\n",
    "          # number of pairs for each atom\n",
    "          pair_split.extend(C1.flatten() + start)\n",
    "          start = start + n_atoms\n",
    "\n",
    "          # atom features\n",
    "          atom_feat.append(mol.get_atom_features())\n",
    "          # pair features\n",
    "          pair_feat.append(\n",
    "              np.reshape(mol.get_pair_features(),\n",
    "                         (n_atoms * n_atoms, self.n_pair_feat)))\n",
    "\n",
    "        feed_dict[self.atom_features] = np.concatenate(atom_feat, axis=0)\n",
    "        feed_dict[self.pair_features] = np.concatenate(pair_feat, axis=0)\n",
    "        feed_dict[self.atom_split] = np.array(atom_split)\n",
    "        feed_dict[self.atom_to_pair] = np.concatenate(atom_to_pair, axis=0)\n",
    "        yield feed_dict\n",
    "\n",
    "      if not predict:\n",
    "        print('Starting validation epoch %i' % epoch)\n",
    "        \n",
    "        if 'mean-mean_absolute_error' in self.evaluate(dataset=dataset, metrics=metrics, transformers=transformers, per_task_metrics=False):\n",
    "            train_metric.append(self.evaluate(dataset=dataset, metrics=metrics, transformers=transformers, per_task_metrics=False)['mean-mean_absolute_error'])\n",
    "            valid_metric.append(self.evaluate(dataset=validdataset, metrics=metrics, transformers=transformers, per_task_metrics=False)['mean-mean_absolute_error'])\n",
    "        \n",
    "  def fit2(self,\n",
    "          dataset,\n",
    "          validdataset,\n",
    "          metrics,\n",
    "          transformers=[],\n",
    "          nb_epoch=10,\n",
    "          max_checkpoints_to_keep=5,\n",
    "          checkpoint_interval=1000,\n",
    "          deterministic=False,\n",
    "          restore=False,\n",
    "          submodel=None,\n",
    "          **kwargs):\n",
    "    \"\"\"Train this model on a dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: Dataset\n",
    "      the Dataset to train on\n",
    "    nb_epoch: int\n",
    "      the number of epochs to train for\n",
    "    max_checkpoints_to_keep: int\n",
    "      the maximum number of checkpoints to keep.  Older checkpoints are discarded.\n",
    "    checkpoint_interval: int\n",
    "      the frequency at which to write checkpoints, measured in training steps.\n",
    "      Set this to 0 to disable automatic checkpointing.\n",
    "    deterministic: bool\n",
    "      if True, the samples are processed in order.  If False, a different random\n",
    "      order is used for each epoch.\n",
    "    restore: bool\n",
    "      if True, restore the model from the most recent checkpoint and continue training\n",
    "      from there.  If False, retrain the model from scratch.\n",
    "    submodel: Submodel\n",
    "      an alternate training objective to use.  This should have been created by\n",
    "      calling create_submodel().\n",
    "    \"\"\"\n",
    "    return self.fit_generator(\n",
    "        self.default_generator(\n",
    "            dataset, validdataset, metrics, transformers=transformers, epochs=nb_epoch, deterministic=deterministic),\n",
    "        max_checkpoints_to_keep, checkpoint_interval, restore, submodel)\n",
    "        \n",
    "\n",
    "        \n",
    "  def default_generator_2(self,\n",
    "                        dataset,\n",
    "                        epochs=1,\n",
    "                        predict=False,\n",
    "                        deterministic=True,\n",
    "                        pad_batches=True):\n",
    "    \"\"\" Same generator as Weave models \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "      if not predict:\n",
    "        print('Starting epoch %i' % epoch)\n",
    "      for (X_b, y_b, w_b, ids_b) in dataset.iterbatches(\n",
    "          batch_size=self.batch_size,\n",
    "          deterministic=deterministic,\n",
    "          pad_batches=pad_batches):\n",
    "\n",
    "        feed_dict = dict()\n",
    "        if y_b is not None:\n",
    "          for index, label in enumerate(self.labels_fd):\n",
    "            if self.mode == \"classification\":\n",
    "              feed_dict[label] = to_one_hot(y_b[:, index])\n",
    "            if self.mode == \"regression\":\n",
    "              feed_dict[label] = y_b[:, index:index + 1]\n",
    "        # w_b act as the indicator of unique samples in the batch\n",
    "        if w_b is not None:\n",
    "          feed_dict[self.weights] = w_b\n",
    "\n",
    "        atom_feat = []\n",
    "        pair_feat = []\n",
    "        atom_split = []\n",
    "        atom_to_pair = []\n",
    "        pair_split = []\n",
    "        start = 0\n",
    "        for im, mol in enumerate(X_b):\n",
    "          n_atoms = mol.get_num_atoms()\n",
    "          # number of atoms in each molecule\n",
    "          atom_split.extend([im] * n_atoms)\n",
    "          # index of pair features\n",
    "          C0, C1 = np.meshgrid(np.arange(n_atoms), np.arange(n_atoms))\n",
    "          atom_to_pair.append(\n",
    "              np.transpose(\n",
    "                  np.array([C1.flatten() + start,\n",
    "                            C0.flatten() + start])))\n",
    "          # number of pairs for each atom\n",
    "          pair_split.extend(C1.flatten() + start)\n",
    "          start = start + n_atoms\n",
    "\n",
    "          # atom features\n",
    "          atom_feat.append(mol.get_atom_features())\n",
    "          # pair features\n",
    "          pair_feat.append(\n",
    "              np.reshape(mol.get_pair_features(),\n",
    "                         (n_atoms * n_atoms, self.n_pair_feat)))\n",
    "\n",
    "        feed_dict[self.atom_features] = np.concatenate(atom_feat, axis=0)\n",
    "        feed_dict[self.pair_features] = np.concatenate(pair_feat, axis=0)\n",
    "        feed_dict[self.atom_split] = np.array(atom_split)\n",
    "        feed_dict[self.atom_to_pair] = np.concatenate(atom_to_pair, axis=0)\n",
    "        yield feed_dict\n",
    "        \n",
    "\n",
    "  def predict(self, dataset, transformers=[], batch_size=None):\n",
    "    # MPNN only accept padded input\n",
    "    generator = self.default_generator_2(dataset, predict=True, pad_batches=True)\n",
    "    return self.predict_on_generator(generator, transformers)\n",
    "\n",
    "  def predict_proba(self, dataset, transformers=[], batch_size=None):\n",
    "    # MPNN only accept padded input\n",
    "    generator = self.default_generator_2(dataset, predict=True, pad_batches=True)\n",
    "    return self.predict_proba_on_generator(generator, transformers)\n",
    "\n",
    "  def predict_proba_on_generator(self, generator, transformers=[]):\n",
    "    \"\"\"\n",
    "            Returns:\n",
    "              y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)\n",
    "            \"\"\"\n",
    "    if not self.built:\n",
    "      self.build()\n",
    "    with self._get_tf(\"Graph\").as_default():\n",
    "      out_tensors = [x.out_tensor for x in self.outputs]\n",
    "      results = []\n",
    "      for feed_dict in generator:\n",
    "        # Extract number of unique samples in the batch from w_b\n",
    "        n_valid_samples = len(np.nonzero(np.sum(feed_dict[self.weights], 1))[0])\n",
    "        feed_dict = {\n",
    "            self.layers[k.name].out_tensor: v\n",
    "            for k, v in six.iteritems(feed_dict)\n",
    "        }\n",
    "        feed_dict[self._training_placeholder] = 0.0\n",
    "        result = np.array(self.session.run(out_tensors, feed_dict=feed_dict))\n",
    "        if len(result.shape) == 3:\n",
    "          result = np.transpose(result, axes=[1, 0, 2])\n",
    "        result = undo_transforms(result, transformers)\n",
    "        # Only fetch the first set of unique samples\n",
    "        results.append(result[:n_valid_samples])\n",
    "      return np.concatenate(results, axis=0)\n",
    "\n",
    "  def predict_on_generator(self, generator, transformers=[]):\n",
    "    return self.predict_proba_on_generator(generator, transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ../ChEMBL/hDAT_pIC50.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "TIMING: featurizing shard 0 took 4.731 s\n",
      "TIMING: dataset construction took 5.380 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import deepchem as dc\n",
    "\n",
    "from deepchem.utils.save import load_from_disk\n",
    "from deepchem.feat.graph_features import ConvMolFeaturizer, WeaveFeaturizer\n",
    "\n",
    "input_data='../ChEMBL/hDAT_pIC50.csv'\n",
    "\n",
    "tasks = ['affinity']\n",
    "featurizer=WeaveFeaturizer()\n",
    "#featurizer=ConvMolFeaturizer()\n",
    "\n",
    "\n",
    "loader = dc.data.CSVLoader(tasks=tasks, smiles_field=\"canonical_smiles\",featurizer=featurizer)\n",
    "dataset=loader.featurize(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMING: dataset construction took 0.730 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.272 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.334 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import tempfile, shutil\n",
    "from deepchem.splits.splitters import RandomSplitter\n",
    "\n",
    "splitter=RandomSplitter()\n",
    "train_data,valid_data,test_data=splitter.train_valid_test_split(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from deepchem.models.tensorgraph.models.graph_models import MPNNTensorGraph, WeaveTensorGraph\n",
    "\n",
    "out_path = '../ChEMBL/hDAT/logdir/'\n",
    "\n",
    "graph_structure = 'MPNN_Default'\n",
    "\n",
    "model_dir = out_path+graph_structure+'/'\n",
    "\n",
    "np.random.seed(0)\n",
    "random_seed = 0\n",
    "\n",
    "model = MPNNTensorGraph(len(tasks), n_atom_feat=75, n_pair_feat=14, n_hidden=100, batch_size=5, mode='regression',random_seed=random_seed)\n",
    "#model = WeaveTensorGraph(len(tasks), dropout=0.5, batch_size=100, mode='regression')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from deepchem.metrics import rms_score\n",
    "\n",
    "metric = dc.metrics.Metric(mean_absolute_error, task_averager=np.mean, mode=\"regression\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nagayasu/anaconda3/envs/deepchem/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:97: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Starting validation epoch 0\n",
      "computed_metrics: [1.0543349062951484]\n",
      "computed_metrics: [1.0543349201409864]\n",
      "computed_metrics: [1.0485199741802325]\n",
      "Starting epoch 1\n",
      "Starting validation epoch 1\n",
      "computed_metrics: [0.6908324674383334]\n",
      "computed_metrics: [0.6908324684514435]\n",
      "computed_metrics: [0.7231504542027012]\n",
      "Starting epoch 2\n",
      "Starting validation epoch 2\n",
      "computed_metrics: [0.7042136433117601]\n",
      "computed_metrics: [0.704213655131378]\n",
      "computed_metrics: [0.7531985078617595]\n",
      "Starting epoch 3\n",
      "Starting validation epoch 3\n",
      "computed_metrics: [0.6867803844521007]\n",
      "computed_metrics: [0.6867803716193727]\n",
      "computed_metrics: [0.7054060495902978]\n",
      "Starting epoch 4\n",
      "Starting validation epoch 4\n",
      "computed_metrics: [1.2799389472154918]\n",
      "computed_metrics: [1.2799389559957794]\n",
      "computed_metrics: [1.2449384519622475]\n",
      "Starting epoch 5\n",
      "Starting validation epoch 5\n",
      "computed_metrics: [0.6793081749583328]\n",
      "computed_metrics: [0.6793081678665621]\n",
      "computed_metrics: [0.7187528503885149]\n",
      "Starting epoch 6\n",
      "Starting validation epoch 6\n",
      "computed_metrics: [0.5845233608921826]\n",
      "computed_metrics: [0.5845233541381152]\n",
      "computed_metrics: [0.6552643004438774]\n",
      "Starting epoch 7\n",
      "Starting validation epoch 7\n",
      "computed_metrics: [0.6492228840813129]\n",
      "computed_metrics: [0.6492228901599736]\n",
      "computed_metrics: [0.6837285287537824]\n",
      "Starting epoch 8\n",
      "Starting validation epoch 8\n",
      "computed_metrics: [0.6135393463588151]\n",
      "computed_metrics: [0.6135393382539343]\n",
      "computed_metrics: [0.6261542624821621]\n",
      "Starting epoch 9\n",
      "Starting validation epoch 9\n",
      "computed_metrics: [0.7098838844532321]\n",
      "computed_metrics: [0.7098838955974434]\n",
      "computed_metrics: [0.7291517282679667]\n",
      "Starting epoch 10\n",
      "Starting validation epoch 10\n",
      "computed_metrics: [0.655152286275102]\n",
      "computed_metrics: [0.6551522822226615]\n",
      "computed_metrics: [0.733386984712671]\n",
      "Starting epoch 11\n",
      "Starting validation epoch 11\n",
      "computed_metrics: [0.5487897759449593]\n",
      "computed_metrics: [0.5487897884399839]\n",
      "computed_metrics: [0.6066340313261345]\n",
      "Starting epoch 12\n",
      "Starting validation epoch 12\n",
      "computed_metrics: [0.5658068579579075]\n",
      "computed_metrics: [0.5658068660627884]\n",
      "computed_metrics: [0.6475812687397322]\n",
      "Starting epoch 13\n",
      "Starting validation epoch 13\n",
      "computed_metrics: [0.5263265266836749]\n",
      "computed_metrics: [0.5263265189164973]\n",
      "computed_metrics: [0.5966806933529205]\n",
      "Starting epoch 14\n",
      "Starting validation epoch 14\n",
      "computed_metrics: [0.5433603333261302]\n",
      "computed_metrics: [0.5433603390670875]\n",
      "computed_metrics: [0.5765955672536311]\n",
      "Starting epoch 15\n",
      "Starting validation epoch 15\n",
      "computed_metrics: [0.566673566595452]\n",
      "computed_metrics: [0.5666735649069351]\n",
      "computed_metrics: [0.6570579065910925]\n",
      "Starting epoch 16\n",
      "Starting validation epoch 16\n",
      "computed_metrics: [0.5220692438285113]\n",
      "computed_metrics: [0.5220692451793248]\n",
      "computed_metrics: [0.5909486048034885]\n",
      "Starting epoch 17\n",
      "Starting validation epoch 17\n",
      "computed_metrics: [0.5693107651869012]\n",
      "computed_metrics: [0.5693107786950359]\n",
      "computed_metrics: [0.6981924298386716]\n",
      "Starting epoch 18\n",
      "Starting validation epoch 18\n",
      "computed_metrics: [0.5993663795597606]\n",
      "computed_metrics: [0.5993663778712437]\n",
      "computed_metrics: [0.681342983123158]\n",
      "Starting epoch 19\n",
      "Starting validation epoch 19\n",
      "computed_metrics: [0.5017856777823809]\n",
      "computed_metrics: [0.501785676093864]\n",
      "computed_metrics: [0.5840733742390088]\n",
      "Starting epoch 20\n",
      "Starting validation epoch 20\n",
      "computed_metrics: [0.5333593808530734]\n",
      "computed_metrics: [0.533359376800633]\n",
      "computed_metrics: [0.6585157756846092]\n",
      "Starting epoch 21\n",
      "Starting validation epoch 21\n",
      "computed_metrics: [0.7126038310862205]\n",
      "computed_metrics: [0.71260382602067]\n",
      "computed_metrics: [0.7992424107275695]\n",
      "Starting epoch 22\n",
      "Starting validation epoch 22\n",
      "computed_metrics: [0.501696602398817]\n",
      "computed_metrics: [0.5016965899037923]\n",
      "computed_metrics: [0.6069794710698375]\n",
      "Starting epoch 23\n",
      "Starting validation epoch 23\n",
      "computed_metrics: [0.5166635304893767]\n",
      "computed_metrics: [0.5166635186697589]\n",
      "computed_metrics: [0.596266567769597]\n",
      "Starting epoch 24\n",
      "Starting validation epoch 24\n",
      "computed_metrics: [0.4952601712599851]\n",
      "computed_metrics: [0.49526017801405253]\n",
      "computed_metrics: [0.6318995627927873]\n",
      "Starting epoch 25\n",
      "Starting validation epoch 25\n",
      "computed_metrics: [0.5798066959185293]\n",
      "computed_metrics: [0.5798067070627405]\n",
      "computed_metrics: [0.6228754751969329]\n",
      "Starting epoch 26\n",
      "Starting validation epoch 26\n",
      "computed_metrics: [0.448939284349199]\n",
      "computed_metrics: [0.44893929380489334]\n",
      "computed_metrics: [0.5409193294625217]\n",
      "Starting epoch 27\n",
      "Starting validation epoch 27\n",
      "computed_metrics: [0.6215867622888971]\n",
      "computed_metrics: [0.6215867470922455]\n",
      "computed_metrics: [0.7466739348713971]\n",
      "Starting epoch 28\n",
      "Starting validation epoch 28\n",
      "computed_metrics: [0.48103081316359353]\n",
      "computed_metrics: [0.48103079830464524]\n",
      "computed_metrics: [0.5524790904816501]\n",
      "Starting epoch 29\n",
      "Starting validation epoch 29\n",
      "computed_metrics: [0.5013721825538225]\n",
      "computed_metrics: [0.5013721926849236]\n",
      "computed_metrics: [0.5655234550133786]\n",
      "Starting epoch 30\n",
      "Starting validation epoch 30\n",
      "computed_metrics: [0.5368341715592597]\n",
      "computed_metrics: [0.536834152647871]\n",
      "computed_metrics: [0.6445211856527485]\n",
      "Starting epoch 31\n",
      "Starting validation epoch 31\n",
      "computed_metrics: [0.5182608140473511]\n",
      "computed_metrics: [0.5182608123588343]\n",
      "computed_metrics: [0.6106899505018166]\n",
      "Starting epoch 32\n",
      "Starting validation epoch 32\n",
      "computed_metrics: [0.46859979300032195]\n",
      "computed_metrics: [0.46859980076749946]\n",
      "computed_metrics: [0.5939217520961264]\n",
      "Starting epoch 33\n",
      "Starting validation epoch 33\n",
      "computed_metrics: [0.48118053143237555]\n",
      "computed_metrics: [0.48118054021266315]\n",
      "computed_metrics: [0.5856563580360977]\n",
      "Starting epoch 34\n",
      "Starting validation epoch 34\n",
      "computed_metrics: [0.5138615253463823]\n",
      "computed_metrics: [0.5138615273726025]\n",
      "computed_metrics: [0.6128814919535829]\n",
      "Starting epoch 35\n",
      "Starting validation epoch 35\n",
      "computed_metrics: [0.44382388630846775]\n",
      "computed_metrics: [0.44382388630846775]\n",
      "computed_metrics: [0.5261857935609574]\n",
      "Starting epoch 36\n",
      "Starting validation epoch 36\n",
      "computed_metrics: [0.45929296953041976]\n",
      "computed_metrics: [0.4592929658156827]\n",
      "computed_metrics: [0.5741494793094353]\n",
      "Starting epoch 37\n",
      "Starting validation epoch 37\n",
      "computed_metrics: [0.46838246104545683]\n",
      "computed_metrics: [0.46838246611100737]\n",
      "computed_metrics: [0.5831574810157754]\n",
      "Starting epoch 38\n",
      "Starting validation epoch 38\n",
      "computed_metrics: [0.42568430062264095]\n",
      "computed_metrics: [0.4256843232487667]\n",
      "computed_metrics: [0.5270474029510884]\n",
      "Starting epoch 39\n",
      "Starting validation epoch 39\n",
      "computed_metrics: [0.4496474915756616]\n",
      "computed_metrics: [0.449647511162457]\n",
      "computed_metrics: [0.5806376660135368]\n",
      "Starting epoch 40\n",
      "Starting validation epoch 40\n",
      "computed_metrics: [0.4138445691018657]\n",
      "computed_metrics: [0.41384458159689036]\n",
      "computed_metrics: [0.541002401575926]\n",
      "Starting epoch 41\n",
      "Starting validation epoch 41\n",
      "computed_metrics: [0.41396632628320024]\n",
      "computed_metrics: [0.41396632527009014]\n",
      "computed_metrics: [0.5463497168495578]\n",
      "Starting epoch 42\n",
      "Starting validation epoch 42\n",
      "computed_metrics: [0.41187063061055124]\n",
      "computed_metrics: [0.41187062790892426]\n",
      "computed_metrics: [0.5057643678239261]\n",
      "Starting epoch 43\n",
      "Starting validation epoch 43\n",
      "computed_metrics: [0.4437579873513973]\n",
      "computed_metrics: [0.4437579927546512]\n",
      "computed_metrics: [0.5550105153120771]\n",
      "Starting epoch 44\n",
      "Starting validation epoch 44\n",
      "computed_metrics: [0.4316279372419607]\n",
      "computed_metrics: [0.4316279369042573]\n",
      "computed_metrics: [0.5484888937338823]\n",
      "Starting epoch 45\n",
      "Starting validation epoch 45\n",
      "computed_metrics: [0.3978726489278427]\n",
      "computed_metrics: [0.3978726310295641]\n",
      "computed_metrics: [0.5752405673378882]\n",
      "Starting epoch 46\n",
      "Starting validation epoch 46\n",
      "computed_metrics: [0.488037918871706]\n",
      "computed_metrics: [0.48803793339295093]\n",
      "computed_metrics: [0.5747909135418136]\n",
      "Starting epoch 47\n",
      "Starting validation epoch 47\n",
      "computed_metrics: [0.45021559072102146]\n",
      "computed_metrics: [0.4502155927472417]\n",
      "computed_metrics: [0.5423164172569961]\n",
      "Starting epoch 48\n",
      "Starting validation epoch 48\n",
      "computed_metrics: [0.5878554235591716]\n",
      "computed_metrics: [0.587855417480511]\n",
      "computed_metrics: [0.6564933414473899]\n",
      "Starting epoch 49\n",
      "Starting validation epoch 49\n",
      "computed_metrics: [0.6833868188822825]\n",
      "computed_metrics: [0.6833868293510869]\n",
      "computed_metrics: [0.7399758155827184]\n",
      "Starting epoch 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 50\n",
      "computed_metrics: [0.4426692295175802]\n",
      "computed_metrics: [0.4426692406617914]\n",
      "computed_metrics: [0.555960331572866]\n",
      "Starting epoch 51\n",
      "Starting validation epoch 51\n",
      "computed_metrics: [0.5673703332045319]\n",
      "computed_metrics: [0.5673703386077859]\n",
      "computed_metrics: [0.6537707880092127]\n",
      "Starting epoch 52\n",
      "Starting validation epoch 52\n",
      "computed_metrics: [0.4326509076638851]\n",
      "computed_metrics: [0.432650919483503]\n",
      "computed_metrics: [0.5401696500786807]\n",
      "Starting epoch 53\n",
      "Starting validation epoch 53\n",
      "computed_metrics: [0.40764664215472324]\n",
      "computed_metrics: [0.40764663843998616]\n",
      "computed_metrics: [0.534905106591656]\n",
      "Starting epoch 54\n",
      "Starting validation epoch 54\n",
      "computed_metrics: [0.4559580157079259]\n",
      "computed_metrics: [0.4559580113177821]\n",
      "computed_metrics: [0.559498174324965]\n",
      "Starting epoch 55\n",
      "Starting validation epoch 55\n",
      "computed_metrics: [0.47171782310697746]\n",
      "computed_metrics: [0.4717178244577909]\n",
      "computed_metrics: [0.5842158954808683]\n",
      "Starting epoch 56\n",
      "Starting validation epoch 56\n",
      "computed_metrics: [0.42150249782919424]\n",
      "computed_metrics: [0.4215024951275673]\n",
      "computed_metrics: [0.5803858932218036]\n",
      "Starting epoch 57\n",
      "Starting validation epoch 57\n",
      "computed_metrics: [0.4543893378207289]\n",
      "computed_metrics: [0.45438933207977156]\n",
      "computed_metrics: [0.6009052986425819]\n",
      "Starting epoch 58\n",
      "Starting validation epoch 58\n",
      "computed_metrics: [0.4459097622836366]\n",
      "computed_metrics: [0.4459097548541625]\n",
      "computed_metrics: [0.5518041483225762]\n",
      "Starting epoch 59\n",
      "Starting validation epoch 59\n",
      "computed_metrics: [0.46063032266593085]\n",
      "computed_metrics: [0.4606303327970319]\n",
      "computed_metrics: [0.588090251657302]\n",
      "Starting epoch 60\n",
      "Starting validation epoch 60\n",
      "computed_metrics: [0.436894680240394]\n",
      "computed_metrics: [0.43689468766986816]\n",
      "computed_metrics: [0.5562583511293255]\n",
      "Starting epoch 61\n",
      "Starting validation epoch 61\n",
      "computed_metrics: [0.43337910338943686]\n",
      "computed_metrics: [0.43337910271403013]\n",
      "computed_metrics: [0.5919783251469909]\n",
      "Starting epoch 62\n",
      "Starting validation epoch 62\n",
      "computed_metrics: [0.42170601276700076]\n",
      "computed_metrics: [0.421706018507958]\n",
      "computed_metrics: [0.5632655179111169]\n",
      "Starting epoch 63\n",
      "Starting validation epoch 63\n",
      "computed_metrics: [0.46545860234823766]\n",
      "computed_metrics: [0.46545861754488926]\n",
      "computed_metrics: [0.5711037454799126]\n",
      "Starting epoch 64\n",
      "Starting validation epoch 64\n",
      "computed_metrics: [0.430631800968525]\n",
      "computed_metrics: [0.43063180941110923]\n",
      "computed_metrics: [0.5770515367723217]\n",
      "Starting epoch 65\n",
      "Starting validation epoch 65\n",
      "computed_metrics: [0.5273036787105208]\n",
      "computed_metrics: [0.5273036733072669]\n",
      "computed_metrics: [0.6474764550897602]\n",
      "Starting epoch 66\n",
      "Starting validation epoch 66\n",
      "computed_metrics: [0.4266810263919825]\n",
      "computed_metrics: [0.426681021326432]\n",
      "computed_metrics: [0.5813255807446563]\n",
      "Starting epoch 67\n",
      "Starting validation epoch 67\n",
      "computed_metrics: [0.4225955205265683]\n",
      "computed_metrics: [0.42259552289049185]\n",
      "computed_metrics: [0.5903602848134554]\n",
      "Starting epoch 68\n",
      "Starting validation epoch 68\n",
      "computed_metrics: [0.4489379191597205]\n",
      "computed_metrics: [0.4489379056515857]\n",
      "computed_metrics: [0.5784761538375741]\n",
      "Starting epoch 69\n",
      "Starting validation epoch 69\n",
      "computed_metrics: [0.5273914817307224]\n",
      "computed_metrics: [0.5273914668717742]\n",
      "computed_metrics: [0.6036336303993467]\n",
      "Starting epoch 70\n",
      "Starting validation epoch 70\n",
      "computed_metrics: [0.39312528962873783]\n",
      "computed_metrics: [0.39312528321237383]\n",
      "computed_metrics: [0.5632513365182134]\n",
      "Starting epoch 71\n",
      "Starting validation epoch 71\n",
      "computed_metrics: [0.4075177076257212]\n",
      "computed_metrics: [0.4075176981700268]\n",
      "computed_metrics: [0.5207842828092543]\n",
      "Starting epoch 72\n",
      "Starting validation epoch 72\n",
      "computed_metrics: [0.5273528089237101]\n",
      "computed_metrics: [0.5273528183794044]\n",
      "computed_metrics: [0.6496549494567926]\n",
      "Starting epoch 73\n",
      "Starting validation epoch 73\n",
      "computed_metrics: [0.4173780474602095]\n",
      "computed_metrics: [0.4173780413815488]\n",
      "computed_metrics: [0.5482531733635847]\n",
      "Starting epoch 74\n",
      "Starting validation epoch 74\n",
      "computed_metrics: [0.40063423161300815]\n",
      "computed_metrics: [0.4006342346523385]\n",
      "computed_metrics: [0.569555914393905]\n",
      "Starting epoch 75\n",
      "Starting validation epoch 75\n",
      "computed_metrics: [0.4115365683514932]\n",
      "computed_metrics: [0.4115365764563741]\n",
      "computed_metrics: [0.5643310241348188]\n",
      "Starting epoch 76\n",
      "Starting validation epoch 76\n",
      "computed_metrics: [0.3806026487564434]\n",
      "computed_metrics: [0.3806026544974007]\n",
      "computed_metrics: [0.538046117176454]\n",
      "Starting epoch 77\n",
      "Starting validation epoch 77\n",
      "computed_metrics: [0.45901692804810745]\n",
      "computed_metrics: [0.45901694493327594]\n",
      "computed_metrics: [0.6174010550445796]\n",
      "Starting epoch 78\n",
      "Starting validation epoch 78\n",
      "computed_metrics: [0.419363174610883]\n",
      "computed_metrics: [0.4193631735977729]\n",
      "computed_metrics: [0.5754977574857837]\n",
      "Starting epoch 79\n",
      "Starting validation epoch 79\n",
      "computed_metrics: [0.4307398982350873]\n",
      "computed_metrics: [0.43073989620886705]\n",
      "computed_metrics: [0.5637342314574092]\n",
      "Starting epoch 80\n",
      "Starting validation epoch 80\n",
      "computed_metrics: [0.49063303327401725]\n",
      "computed_metrics: [0.49063302077899257]\n",
      "computed_metrics: [0.5788894833272861]\n",
      "Starting epoch 81\n",
      "Starting validation epoch 81\n",
      "computed_metrics: [0.45234573402547973]\n",
      "computed_metrics: [0.4523457272714123]\n",
      "computed_metrics: [0.6364396788617313]\n",
      "Starting epoch 82\n",
      "Starting validation epoch 82\n",
      "computed_metrics: [0.49739838756797783]\n",
      "computed_metrics: [0.49739838993190144]\n",
      "computed_metrics: [0.6469892293945184]\n",
      "Starting epoch 83\n",
      "Starting validation epoch 83\n",
      "computed_metrics: [0.3597757400667875]\n",
      "computed_metrics: [0.35977573331272006]\n",
      "computed_metrics: [0.562332531473404]\n",
      "Starting epoch 84\n",
      "Starting validation epoch 84\n",
      "computed_metrics: [0.4131458171758908]\n",
      "computed_metrics: [0.4131458097464166]\n",
      "computed_metrics: [0.6060116823020607]\n",
      "Starting epoch 85\n",
      "Starting validation epoch 85\n",
      "computed_metrics: [0.38166852139908264]\n",
      "computed_metrics: [0.38166851261879503]\n",
      "computed_metrics: [0.5442005207918144]\n",
      "Starting epoch 86\n",
      "Starting validation epoch 86\n",
      "computed_metrics: [0.39222991398387314]\n",
      "computed_metrics: [0.3922299018265518]\n",
      "computed_metrics: [0.5388113402534208]\n",
      "Starting epoch 87\n",
      "Starting validation epoch 87\n",
      "computed_metrics: [0.4538376006429534]\n",
      "computed_metrics: [0.4538376073970208]\n",
      "computed_metrics: [0.614612295538319]\n",
      "Starting epoch 88\n",
      "Starting validation epoch 88\n",
      "computed_metrics: [0.43479442104927274]\n",
      "computed_metrics: [0.43479441074931996]\n",
      "computed_metrics: [0.5939993015480659]\n",
      "Starting epoch 89\n",
      "Starting validation epoch 89\n",
      "computed_metrics: [0.3978616529954081]\n",
      "computed_metrics: [0.3978616654904328]\n",
      "computed_metrics: [0.5830150238884519]\n",
      "Starting epoch 90\n",
      "Starting validation epoch 90\n",
      "computed_metrics: [0.40869486011605005]\n",
      "computed_metrics: [0.40869485944064327]\n",
      "computed_metrics: [0.5688437874045389]\n",
      "Starting epoch 91\n",
      "Starting validation epoch 91\n",
      "computed_metrics: [0.3893210869545757]\n",
      "computed_metrics: [0.38932106838089037]\n",
      "computed_metrics: [0.5561630273288357]\n",
      "Starting epoch 92\n",
      "Starting validation epoch 92\n",
      "computed_metrics: [0.35326824950298796]\n",
      "computed_metrics: [0.35326824747676777]\n",
      "computed_metrics: [0.5447027567886296]\n",
      "Starting epoch 93\n",
      "Starting validation epoch 93\n",
      "computed_metrics: [0.3866661241912952]\n",
      "computed_metrics: [0.3866661417518704]\n",
      "computed_metrics: [0.5517733534685849]\n",
      "Starting epoch 94\n",
      "Starting validation epoch 94\n",
      "computed_metrics: [0.3913494371226074]\n",
      "computed_metrics: [0.39134944083734446]\n",
      "computed_metrics: [0.5815398209906388]\n",
      "Starting epoch 95\n",
      "Starting validation epoch 95\n",
      "computed_metrics: [0.4149647611773151]\n",
      "computed_metrics: [0.41496476624286566]\n",
      "computed_metrics: [0.5560080181117222]\n",
      "Starting epoch 96\n",
      "Starting validation epoch 96\n",
      "computed_metrics: [0.3740604168011927]\n",
      "computed_metrics: [0.37406042152903984]\n",
      "computed_metrics: [0.5687274781526233]\n",
      "Starting epoch 97\n",
      "Starting validation epoch 97\n",
      "computed_metrics: [0.3703573511788525]\n",
      "computed_metrics: [0.3703573275396166]\n",
      "computed_metrics: [0.546347291217355]\n",
      "Starting epoch 98\n",
      "Starting validation epoch 98\n",
      "computed_metrics: [0.35453838853848024]\n",
      "computed_metrics: [0.35453836591235444]\n",
      "computed_metrics: [0.5430053586742303]\n",
      "Starting epoch 99\n",
      "Starting validation epoch 99\n",
      "computed_metrics: [0.4593347318789399]\n",
      "computed_metrics: [0.4593347433608545]\n",
      "computed_metrics: [0.6077081947579264]\n",
      "Starting epoch 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation epoch 100\n",
      "computed_metrics: [0.4284584983780834]\n",
      "computed_metrics: [0.4284585041190407]\n",
      "computed_metrics: [0.5836844169010063]\n",
      "Starting epoch 101\n",
      "Starting validation epoch 101\n",
      "computed_metrics: [0.38196105802103925]\n",
      "computed_metrics: [0.3819610637619965]\n",
      "computed_metrics: [0.5468701791940783]\n",
      "Starting epoch 102\n",
      "Starting validation epoch 102\n",
      "computed_metrics: [0.41728691626151887]\n",
      "computed_metrics: [0.41728691457300204]\n",
      "computed_metrics: [0.5781388939144937]\n",
      "Starting epoch 103\n",
      "Starting validation epoch 103\n",
      "computed_metrics: [0.4108768009836061]\n",
      "computed_metrics: [0.41087681111470725]\n",
      "computed_metrics: [0.5866835779883748]\n",
      "Starting epoch 104\n",
      "Starting validation epoch 104\n",
      "computed_metrics: [0.36788063621157924]\n",
      "computed_metrics: [0.36788062641818153]\n",
      "computed_metrics: [0.5637686278878744]\n",
      "Starting epoch 105\n",
      "Starting validation epoch 105\n",
      "computed_metrics: [0.3532514365999009]\n",
      "computed_metrics: [0.3532514274819099]\n",
      "computed_metrics: [0.495704455640011]\n",
      "Starting epoch 106\n",
      "Starting validation epoch 106\n",
      "computed_metrics: [0.4498789322422115]\n",
      "computed_metrics: [0.4498789339307283]\n",
      "computed_metrics: [0.5632265906094346]\n",
      "Starting epoch 107\n",
      "Starting validation epoch 107\n",
      "computed_metrics: [0.4574915325484196]\n",
      "computed_metrics: [0.4574915105977006]\n",
      "computed_metrics: [0.5942123083014563]\n",
      "Starting epoch 108\n",
      "Starting validation epoch 108\n",
      "computed_metrics: [0.3625099787369452]\n",
      "computed_metrics: [0.36250998616641933]\n",
      "computed_metrics: [0.5276568165236928]\n",
      "Starting epoch 109\n",
      "Starting validation epoch 109\n",
      "computed_metrics: [0.44518977526204184]\n",
      "computed_metrics: [0.4451897688456778]\n",
      "computed_metrics: [0.5908143175845598]\n",
      "Starting epoch 110\n",
      "Starting validation epoch 110\n",
      "computed_metrics: [0.42074434848150905]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit2(train_data, valid_data, metrics=[metric], nb_epoch=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_data, metrics=[metric])\n",
    "model.evaluate(valid_data, metrics=[metric])\n",
    "model.evaluate(test_data, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_score = np.array(train_metric)\n",
    "valid_score = np.array(valid_metric)\n",
    "\n",
    "best_epoch = valid_score.argmin()\n",
    "best_valid_score = valid_score.min()\n",
    "\n",
    "score_summary = np.vstack((valid_score,train_score))\n",
    "\n",
    "print(best_epoch)\n",
    "print(best_valid_score)\n",
    "print(train_score)\n",
    "print(valid_score)\n",
    "print(score_summary)\n",
    "print(np.rot90(score_summary,-1))\n",
    "\n",
    "\n",
    "\n",
    "out_filename = out_path+graph_structure + '_500epochs_summary.csv'\n",
    "\n",
    "np.savetxt(out_filename, np.rot90(score_summary,-1), delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MPNNTensorGraph(len(tasks), n_atom_feat=75, n_pair_feat=14, n_hidden=100, batch_size=5, mode='regression',random_seed=random_seed)\n",
    "model2.fit2(train_data, valid_data, metrics=[metric], nb_epoch=best_epoch+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(train_data, metrics=[metric])\n",
    "model2.evaluate(valid_data, metrics=[metric])\n",
    "model2.evaluate(test_data, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "a1 = np.reshape(train_data.ids, (-1,1))\n",
    "a2 = np.reshape(model2.predict(train_data), (-1,1))\n",
    "a3 = train_data.y\n",
    "\n",
    "print(np.shape(a1))\n",
    "print(np.shape(a2))\n",
    "print(np.shape(a3))\n",
    "\n",
    "\n",
    "a4 = np.concatenate((a1,a2,a3), axis=1)\n",
    "#print(np.shape(a4))\n",
    "#print(a4)\n",
    "\n",
    "plt.scatter(a4[:,2], a4[:,1])\n",
    "plt.title(\"hDAT pIC50\")\n",
    "plt.xlabel(\"true pIC50\")\n",
    "plt.ylabel(\"predicted pIC50\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a11 = np.reshape(valid_data.ids, (-1,1))\n",
    "a21 = np.reshape(model2.predict(valid_data), (-1,1))\n",
    "a31 = valid_data.y\n",
    "\n",
    "a41 = np.concatenate((a11,a21,a31), axis=1)\n",
    "#print(np.shape(a41))\n",
    "#print(a41)\n",
    "\n",
    "plt.scatter(a41[:,2], a41[:,1],s=10)\n",
    "plt.title(\"hDAT pIC50\")\n",
    "plt.xlabel(\"true pIC50\")\n",
    "plt.ylabel(\"predicted pIC50\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a12 = np.reshape(test_data.ids, (-1,1))\n",
    "a22 = np.reshape(model2.predict(test_data), (-1,1))\n",
    "a32 = test_data.y\n",
    "\n",
    "a42 = np.concatenate((a12,a22,a32), axis=1)\n",
    "#print(np.shape(a42))\n",
    "#print(a42)\n",
    "\n",
    "plt.scatter(a42[:,2], a42[:,1],s=10)\n",
    "plt.title(\"hDAT pIC50\")\n",
    "plt.xlabel(\"true pIC50\")\n",
    "plt.ylabel(\"predicted pIC50\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "x = a4[:,1].astype(np.float32)\n",
    "y = a4[:,2].astype(np.float32)\n",
    "\n",
    "print(pearsonr(x,y))\n",
    "print(spearmanr(x,y))\n",
    "\n",
    "x = a41[:,1].astype(np.float32)\n",
    "y = a41[:,2].astype(np.float32)\n",
    "\n",
    "print(pearsonr(x,y))\n",
    "print(spearmanr(x,y))\n",
    "\n",
    "x = a42[:,1].astype(np.float32)\n",
    "y = a42[:,2].astype(np.float32)\n",
    "\n",
    "print(pearsonr(x,y))\n",
    "print(spearmanr(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
