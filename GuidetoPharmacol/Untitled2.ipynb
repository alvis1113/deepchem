{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ./gtop_smiles_processed_1.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "TIMING: featurizing shard 0 took 0.216 s\n",
      "TIMING: dataset construction took 0.251 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import deepchem as dc\n",
    "from deepchem.models.tensorgraph.models.graph_models import GraphConvTensorGraph\n",
    "from deepchem.utils.save import load_from_disk\n",
    "from deepchem.feat.graph_features import ConvMolFeaturizer\n",
    "\n",
    "input_data='./gtop_smiles_processed_1.csv'\n",
    "\n",
    "tasks = ['affinity_class']\n",
    "featurizer=ConvMolFeaturizer()\n",
    "\n",
    "loader = dc.data.CSVLoader(tasks=tasks, smiles_field=\"SMILES\",featurizer=featurizer)\n",
    "dataset=loader.featurize(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMING: dataset construction took 0.033 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.017 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.017 s\n",
      "Loading dataset from disk.\n",
      "<deepchem.data.datasets.DiskDataset object at 0x7f67ba78ae10>\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import tempfile, shutil\n",
    "from deepchem.splits.splitters import IndexSplitter,SingletaskStratifiedSplitter\n",
    "\n",
    "splitter=SingletaskStratifiedSplitter(task_number=0)\n",
    "train_data,valid_data,test_data=splitter.train_valid_test_split(dataset)\n",
    "\n",
    "\n",
    "\n",
    "len(train_data),len(valid_data),len(test_data)\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nagayasu/anaconda3/envs/deepchem/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:97: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.499234747886657"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepchem.models.tensorgraph.models.graph_models import GraphConvTensorGraph\n",
    "\n",
    "model = GraphConvTensorGraph(len(tasks), batch_size=20, dropout=0.5, mode='regression')\n",
    "\n",
    "model.fit(train_data, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model\n",
      "computed_metrics: [0.6019950209182436]\n",
      "computed_metrics: [0.5973943111328058]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from deepchem.metrics import rms_score\n",
    "import deepchem.hyper.grid_search\n",
    "\n",
    "metric = dc.metrics.Metric(\n",
    "    rms_score, task_averager=np.mean, mode=\"regression\")\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "train_scores = model.evaluate(train_data, [metric])\n",
    "\n",
    "valid_scores = model.evaluate(valid_data, [metric])\n",
    "\n",
    "a = model.predict(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ./gtop_smiles_processed_1.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "TIMING: featurizing shard 0 took 0.214 s\n",
      "TIMING: dataset construction took 0.246 s\n",
      "Loading dataset from disk.\n",
      "[[ 0.439663  ]\n",
      " [-0.213216  ]\n",
      " [ 0.00950846]\n",
      " [ 0.47989163]\n",
      " [ 0.4552202 ]\n",
      " [ 0.59154326]\n",
      " [ 0.25048068]\n",
      " [ 0.10327178]\n",
      " [ 0.7048497 ]\n",
      " [ 0.30651113]\n",
      " [-0.05924336]\n",
      " [-0.0902192 ]\n",
      " [ 0.4349831 ]\n",
      " [ 0.03276568]\n",
      " [ 0.38629183]\n",
      " [-0.062916  ]\n",
      " [ 0.51237494]\n",
      " [ 0.3881063 ]\n",
      " [ 0.32358196]\n",
      " [-0.10774159]\n",
      " [-0.13374181]\n",
      " [-0.28967202]\n",
      " [-0.09077056]\n",
      " [ 0.26112893]\n",
      " [ 0.3459794 ]\n",
      " [-0.09177215]\n",
      " [-0.08467265]\n",
      " [ 0.00703882]\n",
      " [ 0.02607217]\n",
      " [ 0.25048068]\n",
      " [-0.09177215]\n",
      " [-0.06212684]\n",
      " [ 0.45261624]\n",
      " [ 0.2166933 ]\n",
      " [ 0.84395534]\n",
      " [ 0.20000796]\n",
      " [-0.3577114 ]\n",
      " [ 0.5416581 ]\n",
      " [ 0.03388848]\n",
      " [ 0.12458321]\n",
      " [ 0.73287606]\n",
      " [ 0.54543567]\n",
      " [ 0.5511099 ]\n",
      " [-0.0972997 ]\n",
      " [-0.19380113]\n",
      " [-0.4332869 ]\n",
      " [ 0.5412897 ]\n",
      " [-0.04290161]\n",
      " [ 0.2197977 ]\n",
      " [-0.4916351 ]\n",
      " [ 0.27717087]\n",
      " [ 0.19833846]\n",
      " [-0.26828992]\n",
      " [ 0.8465779 ]\n",
      " [ 0.5706122 ]\n",
      " [ 0.06164528]\n",
      " [ 0.82217014]\n",
      " [ 0.03206649]\n",
      " [-0.15361126]\n",
      " [ 0.44892153]\n",
      " [ 0.04499201]\n",
      " [ 0.08277883]\n",
      " [ 0.35173243]\n",
      " [ 0.02717143]\n",
      " [ 0.02717143]\n",
      " [-0.16477905]\n",
      " [ 0.46689323]\n",
      " [ 0.2032267 ]\n",
      " [ 0.20299223]\n",
      " [-0.30034456]\n",
      " [ 0.2860526 ]\n",
      " [ 0.6088464 ]\n",
      " [ 0.72667825]\n",
      " [ 0.10258394]\n",
      " [ 0.04285163]\n",
      " [-0.06416966]\n",
      " [ 0.6603613 ]\n",
      " [ 0.35239074]\n",
      " [ 0.89324045]\n",
      " [ 0.42361704]\n",
      " [ 0.23254244]\n",
      " [-0.48210242]\n",
      " [-0.55719286]\n",
      " [ 0.15597393]\n",
      " [ 0.01318841]\n",
      " [ 0.2755232 ]\n",
      " [-0.03207756]\n",
      " [-0.31947288]\n",
      " [ 0.06772414]\n",
      " [ 0.00176046]\n",
      " [ 0.4052095 ]\n",
      " [-0.27693525]\n",
      " [ 0.33886376]\n",
      " [ 0.62112117]\n",
      " [ 0.03425094]\n",
      " [-0.11068211]\n",
      " [-0.02485689]\n",
      " [ 0.15461598]\n",
      " [ 0.07179765]\n",
      " [ 0.63050103]\n",
      " [ 0.39302436]\n",
      " [-0.5422097 ]\n",
      " [-0.12996693]\n",
      " [ 0.05503225]\n",
      " [ 0.44892153]\n",
      " [ 0.44778326]\n",
      " [ 0.89324045]\n",
      " [ 0.89324045]\n",
      " [ 0.4222111 ]\n",
      " [ 0.5144439 ]\n",
      " [ 0.16773687]\n",
      " [ 0.28978962]\n",
      " [-0.10513577]\n",
      " [ 0.36309928]\n",
      " [ 0.5605631 ]\n",
      " [ 0.38160935]\n",
      " [ 0.38503492]\n",
      " [ 0.42839196]\n",
      " [ 0.30578262]]\n"
     ]
    }
   ],
   "source": [
    "test_set=loader.featurize(input_data)\n",
    "\n",
    "b = model.predict(test_set)\n",
    "\n",
    "print(b)\n",
    "\n",
    "np.savetxt(\"./test_set.csv\",b,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
